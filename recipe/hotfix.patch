From 79ccce1b79e8ee7e179214d20d5782fe7e93fad3 Mon Sep 17 00:00:00 2001
From: huikyole <huikyole@argo.jpl.nasa.gov>
Date: Wed, 10 May 2017 11:19:00 -0700
Subject: [PATCH 1/4] CLIMATE-913 - Bugs in CLI

All of the options shown in the run screen work after applying this fix.
---
 RCMES/cli_app.py |   16 ++++------------
 1 file changed, 4 insertions(+), 12 deletions(-)

diff --git a/RCMES/cli_app.py b/RCMES/cli_app.py
index 58e8cb2..0616571 100644
--- a/RCMES/cli_app.py
+++ b/RCMES/cli_app.py
@@ -1185,8 +1185,6 @@ def settings_screen(header):
          screen.addstr(11, x/2, "6 - Change Target dataset/s")
          screen.addstr(12, x/2, "7 - Change Metric")
          screen.addstr(13, x/2, "8 - Change Working Directory")
-         #screen.addstr(14, x/2, "9 - Change Plot Title [Coming Soon....]")
-         #screen.addstr(15, x/2, "10 - Save the processed data [Coming Soon....]")
          screen.addstr(14, x/2, "9 - Show Temporal Boundaries")
          screen.addstr(15, x/2, "10 - Show Spatial Boundaries")
          screen.addstr(16, x/2, "0 - Return to Main Menu")
@@ -1378,18 +1376,11 @@ def settings_screen(header):
                    note = "Working directory has not changed"
 
          if option == '9':
-              screen.addstr(25, x/2, "Please enter plot title:")
-              plot_title = screen.getstr()
-
-         #if option == '10':
-         #     screen.addstr(25, x/2, "Please enter plot title:")
-         #     plot_title = screen.getstr()
-
-         if option == '9':
               models_start_time, models_end_time = get_models_temp_bound()
               line = 25
               for i, model in enumerate(model_datasets):
-                   mode_name = models_info[i]['directory'].split("/")[-1]
+                   #mode_name = models_info[i]['directory'].split("/")[-1]
+                   mode_name = 'model %d' %(i+1)
                    line += 1
                    screen.addstr(line, x/2, "{0}".format(mode_name))
                    line += 1
@@ -1407,7 +1398,8 @@ def settings_screen(header):
               models_bound = get_models_spatial_bound()
               line = 25
               for i, model in enumerate(model_datasets):
-                   mode_name = models_info[i]['directory'].split("/")[-1]
+                   #mode_name = models_info[i]['directory'].split("/")[-1]
+                   mode_name = 'model %d' %(i+1)
                    line += 1
                    screen.addstr(line, x/2, "{0}".format(mode_name))
                    line += 1
-- 
1.7.9.5


From 6cd5c1d4ef2177750d259943f369a5e2928040fc Mon Sep 17 00:00:00 2001
From: huikyole <huikyole@argo.jpl.nasa.gov>
Date: Wed, 10 May 2017 16:23:05 -0700
Subject: [PATCH 2/4] CLIMATE-914 - Update dataset_processor.spatial_regrid
 module

- map_coordinates has been replaced with scipy.interpolate.griddata.
---
 ocw/dataset_processor.py |   90 ++++++++++++++++------------------------------
 1 file changed, 30 insertions(+), 60 deletions(-)

diff --git a/ocw/dataset_processor.py b/ocw/dataset_processor.py
index 917419e..2097cc4 100755
--- a/ocw/dataset_processor.py
+++ b/ocw/dataset_processor.py
@@ -21,7 +21,7 @@ import ocw.utils as utils
 import datetime
 import numpy as np
 import numpy.ma as ma
-import scipy.interpolate
+from scipy.interpolate import griddata
 import scipy.ndimage
 from scipy.stats import rankdata
 from scipy.ndimage import map_coordinates
@@ -222,10 +222,7 @@ def spatial_regrid(target_dataset, new_latitudes, new_longitudes,
 
     # Make masked array of shape (times, new_latitudes,new_longitudes)
     new_values = ma.zeros([len(target_dataset.times),
-                           ny_new, nx_new])
-    # Make masked array of shape (times, new_latitudes,new_longitudes)
-    new_values = ma.zeros([len(target_dataset.times),
-                           ny_new, nx_new])
+                           ny_new, nx_new])+1.e+20
 
     # Boundary vertices of target_dataset
     vertices = []
@@ -249,81 +246,54 @@ def spatial_regrid(target_dataset, new_latitudes, new_longitudes,
         for ix in np.arange(nx_old)[::-1]:
             vertices.append([lons[0, ix], lats[0, ix]])
     path = Path(vertices)
-
-    # Convert new_lats and new_lons to float indices
-    new_lons_indices = np.zeros(new_lons.shape)
-    new_lats_indices = np.zeros(new_lats.shape)
+    new_xy_mask = np.ones(new_lats.shape)
 
     for iy in np.arange(ny_new):
         for ix in np.arange(nx_new):
             if path.contains_point([new_lons[iy, ix],
                                     new_lats[iy, ix]]) or not boundary_check:
-                if regular_grid:
-                    mn = lats.min()
-                    mx = lats.max()
-                    new_lats_indices[iy, ix] = (
-                        ny_old - 1.) * (new_lats[iy, ix] - mn) / (mx - mn)
-                    mn = lons.min()
-                    mx = lons.max()
-                    new_lons_indices[iy, ix] = (
-                        nx_old - 1.) * (new_lons[iy, ix] - mn) / (mx - mn)
-                else:
-                    distance_from_original_grids = (
-                        (lons - new_lons[iy, ix])**2. +
-                        (lats - new_lats[iy, ix])**2.)**0.5
-                    if np.min(distance_from_original_grids) == 0.:
-                        new_lats_indices[iy, ix], new_lons_indices[
-                            iy, ix] = np.where(
-                                distance_from_original_grids == 0)
-                    else:
-                        distance_rank = rankdata(
-                            distance_from_original_grids.flatten(),
-                            method='ordinal').reshape(lats.shape)
-                        # the nearest grid point's indices
-                        iy1, ix1 = np.where(distance_rank == 1)
-                        # point [iy2, ix] is diagonally across from [iy1, ix1]
-                        iy2, ix2 = np.where(distance_rank == 4)
-                        dist1 = distance_from_original_grids[iy1, ix1]
-                        dist2 = distance_from_original_grids[iy2, ix2]
-                        new_lats_indices[iy, ix] = (
-                            dist1 * iy2 + dist2 * iy1) / (dist1 + dist2)
-                        new_lons_indices[iy, ix] = (
-                            dist1 * ix2 + dist2 * ix1) / (dist1 + dist2)
-            else:
-                new_lats_indices[iy, ix] = -999.
-                new_lats_indices[iy, ix] = -999.
-    new_lats_indices = ma.masked_less(new_lats_indices, 0.)
-    new_lons_indices = ma.masked_less(new_lons_indices, 0.)
-
+               new_xy_mask[iy, ix] = 0.
+            
+    new_index = np.where(new_xy_mask == 0.)
     # Regrid the data on each time slice
     for i in range(len(target_dataset.times)):
         if len(target_dataset.times) == 1 and target_dataset.values.ndim == 2:
             values_original = ma.array(target_dataset.values)
         else:
             values_original = ma.array(target_dataset.values[i])
+        new_mask = np.copy(values_original.mask)
         for shift in (-1, 1):
             for axis in (0, 1):
                 q_shifted = np.roll(values_original, shift=shift, axis=axis)
-                idx = ~q_shifted.mask * values_original.mask
-                indices = np.where(idx)[0]
-                values_original.data[indices] = q_shifted[indices]
-        new_values[i] = map_coordinates(values_original,
-                                        [new_lats_indices.flatten(),
-                                         new_lons_indices.flatten()],
-                                        order=1).reshape(new_lats.shape)
-        new_values[i] = ma.array(new_values[i], mask=new_lats_indices.mask)
+                if (np.where((values_original.mask == True) & (q_shifted.mask == False)))[0].size !=0:
+                    index1 =np.where((values_original.mask == True) & (q_shifted.mask == False))
+                    n_indices = len(index1[0])
+                    values_original.data[index1] = q_shifted[index1]
+                    new_mask[index1] = np.repeat(False, n_indices)
+                    mask_index = np.where(~new_mask)
+        if new_mask.size != 1:
+            mask_index = np.where(~new_mask)
+        else:
+            mask_index = np.where(~np.isnan(values_original))
+        new_values_temp = griddata((lons[mask_index], lats[mask_index]), values_original[mask_index],
+                              (new_lons[new_index],
+                               new_lats[new_index]),
+                               method='linear')
         # Make a masking map using nearest neighbour interpolation -use this to
         # determine locations with MDI and mask these
         qmdi = np.zeros_like(values_original)
-        values_true_indices = np.where(values_original.mask == True)[0]
-        values_false_indices = np.where(values_original.mask == False)[0]
+        values_true_indices = np.where(values_original.mask == True)
+        values_false_indices = np.where(values_original.mask == False)
         qmdi[values_true_indices] = 1.
         qmdi[values_false_indices] = 0.
-        qmdi_r = map_coordinates(qmdi, [new_lats_indices.flatten(
-        ), new_lons_indices.flatten()], order=1).reshape(new_lats.shape)
-        mdimask = (qmdi_r != 0.0)
+        qmdi_r = griddata((lons.flatten(), lats.flatten()), qmdi.flatten(), 
+                             (new_lons[new_index],
+                              new_lats[new_index]),
+                              method='nearest')
+        new_values_temp = ma.masked_where(qmdi_r != 0.0, new_values_temp)
         # Combine missing data mask, with outside domain mask define above.
-        new_values[i].mask = np.logical_or(mdimask, new_values[i].mask)
+        new_values[i, new_index[0], new_index[1]] = new_values_temp[:]
+        new_values[i,:] = ma.masked_equal(new_values[i,:], 1.e+20)
 
     # TODO:
     # This will call down to the _congrid() function and the lat and lon
-- 
1.7.9.5


From ee5f3c26fb1d4009325028bda4b29536b14a0319 Mon Sep 17 00:00:00 2001
From: huikyole <huikyole@argo.jpl.nasa.gov>
Date: Wed, 10 May 2017 21:45:06 -0700
Subject: [PATCH 3/4] the unreasonable reshaping of latitude and longitude was
 replaced by the numpy.meshgrid

---
 ocw/tests/test_dataset_processor.py |    6 ++----
 1 file changed, 2 insertions(+), 4 deletions(-)

diff --git a/ocw/tests/test_dataset_processor.py b/ocw/tests/test_dataset_processor.py
index 32fa42d..27af951 100644
--- a/ocw/tests/test_dataset_processor.py
+++ b/ocw/tests/test_dataset_processor.py
@@ -391,10 +391,8 @@ class TestSpatialRegrid(unittest.TestCase):
                           self.regridded_dataset.variable)
 
     def test_two_dimensional_lats_lons(self):
-        self.input_dataset.lats = np.array(range(-89, 90, 2))
-        self.input_dataset.lons = np.array(range(-179, 180, 4))
-        self.input_dataset.lats = self.input_dataset.lats.reshape(2, 45)
-        self.input_dataset.lons = self.input_dataset.lons.reshape(2, 45)
+        self.input_dataset.lons, self.input_dataset.lats = np.meshgrid(
+                                  np.array(range(-179, 180, 2)), np.array(range(-89, 90, 2)))
         new_dataset = dp.spatial_regrid(
             self.input_dataset, self.new_lats, self.new_lons)
         np.testing.assert_array_equal(new_dataset.lats, self.new_lats)
-- 
1.7.9.5


From e84bd1839dbbeb7bd64a9cd837e0895a0c86e092 Mon Sep 17 00:00:00 2001
From: huikyole <huikyole@argo.jpl.nasa.gov>
Date: Thu, 11 May 2017 13:22:11 -0700
Subject: [PATCH 4/4] CLIMATE-915 - Updates for the NARCCAP example
 configuration files

- Fig14_and_Fig15.yaml, Fig16_summer.yaml, and Fig16_winter.yaml have been updated.
---
 .../NARCCAP_examples/Fig14_and_Fig15.yaml          |    4 +++-
 .../NARCCAP_examples/Fig16_summer.yaml             |    5 +++--
 .../NARCCAP_examples/Fig16_winter.yaml             |    4 +++-
 3 files changed, 9 insertions(+), 4 deletions(-)

diff --git a/RCMES/configuration_files/NARCCAP_examples/Fig14_and_Fig15.yaml b/RCMES/configuration_files/NARCCAP_examples/Fig14_and_Fig15.yaml
index 83a2e32..11410a2 100644
--- a/RCMES/configuration_files/NARCCAP_examples/Fig14_and_Fig15.yaml
+++ b/RCMES/configuration_files/NARCCAP_examples/Fig14_and_Fig15.yaml
@@ -22,9 +22,11 @@ regrid:
     regrid_dlat: 0.50
     regrid_dlon: 0.50
 
+# generic_dataset_name: If false, data filenames must include the elements of dataset_name list. 
 datasets:
   - loader_name: local
-    name: SRB
+    generic_dataset_name: True
+    dataset_name: ['SRB']
     file_path: ./data/NARCCAP_data/srb_rel3.0_shortwave_from_1983_to_2007.nc
     variable_name: sw_sfc_dn
 
diff --git a/RCMES/configuration_files/NARCCAP_examples/Fig16_summer.yaml b/RCMES/configuration_files/NARCCAP_examples/Fig16_summer.yaml
index dca3c00..05cda15 100644
--- a/RCMES/configuration_files/NARCCAP_examples/Fig16_summer.yaml
+++ b/RCMES/configuration_files/NARCCAP_examples/Fig16_summer.yaml
@@ -21,10 +21,11 @@ regrid:
     regrid_on_reference: False
     regrid_dlat: 0.50
     regrid_dlon: 0.50
-
+# generic_dataset_name: If false, data filenames must include the elements of dataset_name list.
 datasets:
   - loader_name: local
-    name: SRB
+    generic_dataset_name: True
+    dataset_name: ['SRB']
     file_path: ./data/NARCCAP_data/srb_rel3.0_shortwave_from_1983_to_2007.nc
     variable_name: sw_sfc_dn
 
diff --git a/RCMES/configuration_files/NARCCAP_examples/Fig16_winter.yaml b/RCMES/configuration_files/NARCCAP_examples/Fig16_winter.yaml
index d6e647f..622bbe3 100644
--- a/RCMES/configuration_files/NARCCAP_examples/Fig16_winter.yaml
+++ b/RCMES/configuration_files/NARCCAP_examples/Fig16_winter.yaml
@@ -22,9 +22,11 @@ regrid:
     regrid_dlat: 0.50
     regrid_dlon: 0.50
 
+# generic_dataset_name: If false, data filenames must include the elements of dataset_name list.
 datasets:
   - loader_name: local
-    name: SRB
+    generic_dataset_name: True
+    dataset_name: ['SRB']
     file_path: ./data/NARCCAP_data/srb_rel3.0_shortwave_from_1983_to_2007.nc
     variable_name: sw_sfc_dn
 
-- 
1.7.9.5

